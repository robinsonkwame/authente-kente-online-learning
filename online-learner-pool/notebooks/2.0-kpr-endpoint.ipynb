{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c4db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from multiprocessing import Process\n",
    "from wait4it import wait_for\n",
    "from typing import List\n",
    "from fastapi.responses import HTMLResponse\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "MY_IP_ADDRESS = '10.0.1.7'\n",
    "PORT = 8080\n",
    "app = FastAPI()\n",
    "\n",
    "def run():\n",
    "    uvicorn.run(app, port=PORT, host=MY_IP_ADDRESS)\n",
    "\n",
    "_api_process = None\n",
    "\n",
    "def start_api():\n",
    "    \"\"\"Stop the API if running; Start the API; Wait until API (port) is available (reachable)\"\"\"\n",
    "    global _api_process\n",
    "    if _api_process:\n",
    "        _api_process.terminate()\n",
    "        _api_process.join()\n",
    "\n",
    "    _api_process = Process(target=run, daemon=True)\n",
    "    _api_process.start()\n",
    "    wait_for(host=MY_IP_ADDRESS,port=PORT)\n",
    "\n",
    "def delete_route(method: str, path: str):\n",
    "    \"\"\"Delete the given route from the API. This must be called on cells that re-define a route\"\"\"\n",
    "    [app.routes.remove(route) for route in app.routes if method in route.methods and route.path == path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c0877b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23432/3873033565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "# following from tests in 1.0-kpr notebook and the FastAPI tutorial here\n",
    "#     https://towardsdatascience.com/image-classification-api-with-tensorflow-and-fastapi-fc85dc6d39e8\n",
    "#\n",
    "# also note issues w TF and predict w/in serving, here\n",
    "# https://stackoverflow.com/questions/58919924/tensorflow-keras-model-served-by-a-flask-app-uwsgi-gets-stuck-in-model-predict\n",
    "# and\n",
    "# https://stackoverflow.com/questions/50906673/keras-model-is-stuck-at-prediction-level-when-running-the-server-with-gunicorn\n",
    "\n",
    "def load_model():\n",
    "    model = tf.keras.applications.MobileNetV2(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=True, \n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    print(\"Model loaded\")\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/12379\n",
    "graph = tf.keras.graph()\n",
    "\n",
    "def predict(image: Image.Image):\n",
    "    with graph.as_default():     #predict here    \n",
    "        image = np.asarray(image.resize((224, 224)))[..., :3]\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = image / 127.5 - 1.0\n",
    "        print('resized image... about to decode predictions...')\n",
    "        result = decode_predictions(model.predict(image), 2)[0]\n",
    "        print('... have result!')    \n",
    "        response = []\n",
    "        for i, res in enumerate(result):\n",
    "            resp = {}\n",
    "            resp[\"class\"] = res[1]\n",
    "            resp[\"confidence\"] = f\"{res[2]*100:0.2f} %\"\n",
    "            response.append(resp)\n",
    "        return response\n",
    "\n",
    "def read_imagefile(file) -> Image.Image:\n",
    "    image = Image.open(BytesIO(file))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict/image\")\n",
    "async def predict_api(files: List[UploadFile] = File(...)):\n",
    "    file = files[0]\n",
    "    extension = file.filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n",
    "    if not extension:\n",
    "        return \"Image must be jpg or png format!\"\n",
    "    image = read_imagefile(await file.read())\n",
    "    prediction = predict(image)\n",
    "    print(prediction)\n",
    "    return prediction\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def main():\n",
    "    content = \"\"\"\n",
    "<body>\n",
    "<form action=\"/predict/image\" enctype=\"multipart/form-data\" method=\"post\" multiple>\n",
    "<input name=\"files\" type=\"file\">\n",
    "<input type=\"submit\">\n",
    "</form>\n",
    "</body>\n",
    "    \"\"\"\n",
    "    return HTMLResponse(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85a43533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [24156]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://10.0.1.7:8080 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     10.0.1.36:61902 - \"GET / HTTP/1.1\" 200 OK\n",
      "resized image... about to decode predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-27 15:07:00.075870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-27 15:07:00.096500: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2098860000 Hz\n"
     ]
    }
   ],
   "source": [
    "start_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a8b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_api_process.terminate()\n",
    "_api_process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf8091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

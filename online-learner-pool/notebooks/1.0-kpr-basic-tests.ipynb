{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db92c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Property 4 check, @David-Lor, see: https://github.com/David-Lor/FastAPI_LightningTalk-Notebook/blob/master/FastAPI.ipynb\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "import socket\n",
    "\n",
    "MY_IP_ADDRESS = '10.0.1.7'\n",
    "PORT = 8080\n",
    "app = FastAPI()\n",
    "\n",
    "def run():\n",
    "    uvicorn.run(app, port=PORT, host=MY_IP_ADDRESS)\n",
    "    \n",
    "from multiprocessing import Process\n",
    "from wait4it import wait_for\n",
    "\n",
    "_api_process = None\n",
    "\n",
    "def start_api():\n",
    "    \"\"\"Stop the API if running; Start the API; Wait until API (port) is available (reachable)\"\"\"\n",
    "    global _api_process\n",
    "    if _api_process:\n",
    "        _api_process.terminate()\n",
    "        _api_process.join()\n",
    "\n",
    "    _api_process = Process(target=run, daemon=True)\n",
    "    _api_process.start()\n",
    "    wait_for(host=MY_IP_ADDRESS,port=PORT)\n",
    "\n",
    "def delete_route(method: str, path: str):\n",
    "    \"\"\"Delete the given route from the API. This must be called on cells that re-define a route\"\"\"\n",
    "    [app.routes.remove(route) for route in app.routes if method in route.methods and route.path == path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb75b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is a test of several properties that are needed \n",
    "# to stand up an end to end pool of online learners\n",
    "from vowpalwabbit import pyvw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "802946cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first vw has 0x7fcc1d9524a0 and second vw has 0x7fcc3471b360\n",
      "first model predicted 0.632030725479126, second predicted  0.0\n"
     ]
    }
   ],
   "source": [
    "# Property 1: Inital test to verify that more than one vw can be used\n",
    "# and that they do not share model memory\n",
    "\n",
    "first_vw = pyvw.vw(quiet=True)\n",
    "second_vw = pyvw.vw(quiet=True)\n",
    "print(f\"first vw has {hex(id(first_vw))} and second vw has {hex(id(second_vw))}\")\n",
    "id(first_vw) == id(second_vw), \"First and second instances point to the same memory!\"\n",
    "\n",
    "# But they don't seem to share model memory? Note how even the examples are in scope of\n",
    "# the instance\n",
    "ex = first_vw.example('1 | a b c')\n",
    "first_vw.learn(ex)\n",
    "\n",
    "first_predict = first_vw.predict(ex)\n",
    "second_predict = second_vw.predict(ex)\n",
    "\n",
    "print(f\"first model predicted {first_predict}, second predicted  {second_predict}\")\n",
    "assert first_predict != second_predict, \"Models seems equivalent because same prediction was given\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b4ecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ...adding towering-kudu\n",
      "\t ...adding ochre-jaybird\n"
     ]
    }
   ],
   "source": [
    "# Property 2: Referencing a config file, create a pool of learners\n",
    "# The pool should be threadsafe (deduction from locked_dict library)\n",
    "from dynaconf import settings\n",
    "import locked_dict.locked_dict as locked_dict\n",
    "from coolname import generate_slug\n",
    "\n",
    "pool_of_learners = locked_dict.LockedDict()\n",
    "\n",
    "a_key = None\n",
    "for _ in range(settings.NUMBER_OF_LEARNERS):\n",
    "    name = generate_slug(2)\n",
    "    print(f\"\\t ...adding {name}\")\n",
    "    pool_of_learners[name] = pyvw.vw(quiet=True)\n",
    "    a_key = name\n",
    "    \n",
    "assert type(pool_of_learners[a_key]) == type(pyvw.vw(quiet=True)), \"Pool contains different types than vw!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b25fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the decision was 1.0\n"
     ]
    }
   ],
   "source": [
    "# Property 3: ImageNet can recieve and output features that a learner can accept\n",
    "\n",
    "# class code attribution @sansi95 (https://github.com/robinsonkwame/kente-cloth-authentication/src/features/feature_processor.py)\n",
    "# modified\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from dynaconf import settings # because we frequently update the file \n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "class FeatureProcessor(ABC):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 flattened_size,\n",
    "                 feature_file_format\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.flattened_size = flattened_size\n",
    "        self.feature_file_format = feature_file_format\n",
    "\n",
    "    @staticmethod\n",
    "    def create(\n",
    "        feature_processor_name,\n",
    "        batch_size,\n",
    "        feature_file_format\n",
    "    ):\n",
    "        if feature_processor_name == \"MobileNet\":\n",
    "            flattened_size = 7 * 7 * 1280\n",
    "            return MobileNetFeatureProcessor(batch_size, flattened_size, feature_file_format)\n",
    "\n",
    "    def initialize_output_processor(self, labels, feature_file_path):\n",
    "        if self.feature_file_format == \"npy\":\n",
    "            self.output_processor = NpyOutput(labels,\n",
    "            self.flattened_size, self.batch_size, feature_file_path)\n",
    "        elif self.feature_file_format == \"csv\":\n",
    "            self.output_processor = CsvOutput(labels,\n",
    "            self.batch_size, feature_file_path)\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_image(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_features(self):\n",
    "        pass\n",
    "\n",
    "class MobileNetFeatureProcessor(FeatureProcessor):\n",
    "    def __init__(self, batch_size, flattened_size, feature_file_format):\n",
    "        super().__init__(batch_size, flattened_size, feature_file_format)\n",
    "        self.model = MobileNetV2(weights=\"imagenet\",\n",
    "                                 include_top=False, \n",
    "                                 input_shape=(224, 224, 3)\n",
    "                    )\n",
    "        self.name = \"mobile\"\n",
    "\n",
    "    def process_image(self, image_path):\n",
    "        image = load_img(\n",
    "            image_path,\n",
    "            target_size=(224, 224)\n",
    "        )\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        return image\n",
    "\n",
    "    def process_in_memory_image(self, image, dsize=(224, 224)):\n",
    "        # See: https://stackoverflow.com/questions/55873174/how-do-i-return-an-image-in-fastapi\n",
    "        image = cv2.resize(image, dsize=dsize)\n",
    "        print('... about to convert to array')        \n",
    "        image = img_to_array(image)        \n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        print('... about to preprocess')                \n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "        print('about to return image...')\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def create_features(self, batch_images):\n",
    "        features = self.model.predict(\n",
    "            batch_images,\n",
    "            batch_size= self.batch_size\n",
    "        )\n",
    "        features = features.reshape(\n",
    "            (features.shape[0], self.flattened_size)\n",
    "        )\n",
    "        return features\n",
    "\n",
    "    def create_features_for_an_image(self, the_image):\n",
    "        print('about to call mobilenet model directly')\n",
    "        features = self.model(\n",
    "            the_image,\n",
    "            training=False\n",
    "        )\n",
    "        print('reshaping mobilenet featurs...')\n",
    "        features = features.reshape(\n",
    "            (features.shape[0], self.flattened_size)\n",
    "        )\n",
    "        return features\n",
    "    \n",
    "    \n",
    "def construct_vw_example(label, features):\n",
    "    return f\"{label} |\" + np.array2string(\n",
    "        features,\n",
    "        precision=4,\n",
    "        separator=' ',\n",
    "        suppress_small=True\n",
    "    )\n",
    "\n",
    "    \n",
    "the_feature_processor = FeatureProcessor.create(\n",
    "        feature_processor_name=settings.FEATURE_PROCESSOR_NAME,\n",
    "        batch_size=settings.BATCH_SIZE,\n",
    "        feature_file_format=None\n",
    ")\n",
    "\n",
    "the_image_features = the_feature_processor.create_features(\n",
    "    the_feature_processor.process_image('./real_miami_a_25.jpg') # note: 2016x2016 size! \n",
    ")\n",
    "assert the_image_features.shape[1] == 7 * 7 * 1280, \"feature vector is not the expected length\"\n",
    "\n",
    "TRUE = 1\n",
    "image_feature_ex = pool_of_learners[a_key].example(\n",
    "    construct_vw_example(TRUE, the_image_features)\n",
    ")\n",
    "pool_of_learners[a_key].learn(image_feature_ex)\n",
    "\n",
    "decision = pool_of_learners[a_key].predict(image_feature_ex)\n",
    "assert decision == TRUE, \"The learned example was predicted to be something other than the example!\"\n",
    "print(f\"the decision was {decision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd6020ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property 4: Stand up an API that passes a list of image files to a learner\n",
    "# Note: this code requires a server to standup, see first block\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "def load_image_into_numpy_array(data):\n",
    "    return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# TODO: create new endpint that teaches\n",
    "# * accepts list of files\n",
    "# X * accepts list of fake/real indicators <--- text box? radio buttons?\n",
    "# * calls image net on them (list of)\n",
    "# * passes as exampels to vw\n",
    "\n",
    "# TODO: create new endpoint that predicts\n",
    "# * accepts list of files\n",
    "# X * accepts list of fake/real indicators\n",
    "# * passes to vw, returns predictions with\n",
    "# * F1 metric, accuracy, etc.\n",
    "\n",
    "# ...\n",
    "# * \n",
    "\n",
    "def get_or_assign_learner():\n",
    "    # to do: associate session or authenticated login\n",
    "    # with\n",
    "    return a_key\n",
    "\n",
    "@app.post(\"/teach/\")\n",
    "async def create_teach(files: List[UploadFile] = File(...), labels: str = Form(...)):\n",
    "    # Todo: move some of these to long running tasks\n",
    "    individual_labels = labels.split(',')\n",
    "\n",
    "    individual_image_features = []\n",
    "    for the_file in files:\n",
    "        print(f\"working on {the_file.filename}\")\n",
    "        image = load_image_into_numpy_array(await the_file.read())\n",
    "        print(f\" loaded to numpy array! {image.shape}\")\n",
    "\n",
    "        image_features =\\\n",
    "                the_feature_processor.create_features_for_an_image(\n",
    "                    the_feature_processor.process_in_memory_image(\n",
    "                        image\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        print(image_features[1])\n",
    "        \n",
    "#         individual_image_features.append(\n",
    "#             the_feature_processor.create_features(\n",
    "#                 the_feature_processor.process_in_memory_image(\n",
    "#                     image\n",
    "#                 )\n",
    "#         )\n",
    "#     )\n",
    "        print(f\"... taught {the_file.filename}!\")\n",
    "\n",
    "    \n",
    "#     a_key = get_or_assign_learner()\n",
    "#     image_feature_ex = pool_of_learners[a_key].example(\n",
    "#         construct_vw_example(TRUE, the_image_features)\n",
    "#     )\n",
    "#     pool_of_learners[a_key].learn(image_feature_ex)\n",
    "\n",
    "#     decision = pool_of_learners[a_key].predict(image_feature_ex)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"files\": [file.filename for file in files],\n",
    "        \"labels\": individual_labels\n",
    "    }\n",
    "    #return {\"filenames\": [file.filename for file in files]}\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def main():\n",
    "    content = \"\"\"\n",
    "<body>\n",
    "<form action=\"/teach/\" enctype=\"multipart/form-data\" method=\"post\">\n",
    "<input name=\"files\" type=\"file\" multiple>\n",
    "<input name=\"labels\" type=\"text\" required>\n",
    "<input type=\"submit\">\n",
    "</form>\n",
    "</body>\n",
    "    \"\"\"\n",
    "    return HTMLResponse(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee7a1db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [16197]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://10.0.1.7:8080 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     10.0.1.36:53964 - \"GET / HTTP/1.1\" 200 OK\n",
      "working on fake_001_0.jpg\n",
      " loaded to numpy array! (224, 224, 3)\n",
      "... about to convert to array\n",
      "... about to preprocess\n",
      "about to return image...\n",
      "about to call mobilenet model directly\n"
     ]
    }
   ],
   "source": [
    "start_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffbd1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems to be deamon'ed or auto-restart\n",
    "_api_process.terminate()\n",
    "_api_process.kill()\n",
    "# Free socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b3a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
